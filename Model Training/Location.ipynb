{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3ca1825",
      "metadata": {},
      "source": [
        "COLLAB SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s2uTcbhO4NLp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2uTcbhO4NLp",
        "outputId": "00b82874-ed08-42bb-d4f9-f470c2b7f74d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "73eca5bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcdf87a0",
      "metadata": {},
      "source": [
        "IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7230d818",
      "metadata": {
        "id": "7230d818"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense,Convolution2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c9b85f9",
      "metadata": {},
      "source": [
        "IMPORTING TRAINING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1ea152",
      "metadata": {
        "id": "5c1ea152"
      },
      "outputs": [],
      "source": [
        "image_generator=ImageDataGenerator(vertical_flip=False,horizontal_flip=True,shear_range=0.1,zoom_range=0.1,rescale=1/255,brightness_range=(0.2,0.8))\n",
        "X_train1=image_generator.flow_from_directory(target_size=(224,224),\n",
        "                                    directory=\"drive/My Drive/Project Data/body/training\",\n",
        "                                    class_mode=\"categorical\",\n",
        "                                   batch_size=10,\n",
        "                                            subset=\"training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e51e10b",
      "metadata": {},
      "source": [
        "IMPORTING TESTING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edac2589",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edac2589",
        "outputId": "9662a791-78d6-4e42-a1f9-ac744ebcee4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 171 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "image_generator_1=ImageDataGenerator(vertical_flip=False,horizontal_flip=True,shear_range=0.1,zoom_range=0.1,rescale=1/255,brightness_range=(0.2,0.8))\n",
        "X_test1=image_generator_1.flow_from_directory(target_size=(224,224),\n",
        "                                    directory=\"drive/My Drive/Project Data/body/validation\",\n",
        "                                    class_mode=\"categorical\",\n",
        "                                   batch_size=10,\n",
        "                                )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d89eabb",
      "metadata": {},
      "source": [
        "INTTIALZE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b07992",
      "metadata": {
        "id": "e0b07992"
      },
      "outputs": [],
      "source": [
        "vgg16=VGG16(include_top=False,input_shape=(224,224,3),weights='imagenet')\n",
        "for i in vgg16.layers:\n",
        "  i.trainable=False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d9232d",
      "metadata": {},
      "source": [
        "ADD FLATTEN LAYER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-ngnDXe-_E0a",
      "metadata": {
        "id": "-ngnDXe-_E0a"
      },
      "outputs": [],
      "source": [
        "flatten_layer=Flatten()(vgg16.output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02ed23d1",
      "metadata": {},
      "source": [
        "ADD DENSE LAYER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ef9bf7",
      "metadata": {},
      "outputs": [],
      "source": [
        "dense32=Dense(32,kernel_initializer=RandomNormal,activation=\"relu\")(flatten_layer)\n",
        "output=Dense(3,activation=\"softmax\")(dense32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a240f1d",
      "metadata": {},
      "source": [
        "CREATE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f5eb2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "model1=Model(inputs=vgg16.input,outputs=output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6203afe0",
      "metadata": {},
      "source": [
        "CONFIGURE LEARNING PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b23fc7",
      "metadata": {
        "id": "37b23fc7"
      },
      "outputs": [],
      "source": [
        "model1.compile(loss=CategoricalCrossentropy(),\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6047139",
      "metadata": {},
      "source": [
        "TRAIN THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d78c53",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3d78c53",
        "outputId": "17966ff5-b597-4a42-c5e9-e2e5f03e6eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "97/97 [==============================] - 584s 6s/step - loss: 1.5552 - accuracy: 0.4727 - val_loss: 1.0637 - val_accuracy: 0.5941\n",
            "Epoch 2/25\n",
            "97/97 [==============================] - 575s 6s/step - loss: 0.9066 - accuracy: 0.6171 - val_loss: 1.1633 - val_accuracy: 0.5471\n",
            "Epoch 3/25\n",
            "97/97 [==============================] - 576s 6s/step - loss: 1.0237 - accuracy: 0.5511 - val_loss: 0.9585 - val_accuracy: 0.5471\n",
            "Epoch 4/25\n",
            "97/97 [==============================] - 577s 6s/step - loss: 0.8211 - accuracy: 0.5955 - val_loss: 0.9118 - val_accuracy: 0.5765\n",
            "Epoch 5/25\n",
            "97/97 [==============================] - 572s 6s/step - loss: 0.7611 - accuracy: 0.6244 - val_loss: 0.9034 - val_accuracy: 0.5529\n",
            "Epoch 6/25\n",
            "97/97 [==============================] - 568s 6s/step - loss: 0.7301 - accuracy: 0.6605 - val_loss: 0.9219 - val_accuracy: 0.5588\n",
            "Epoch 7/25\n",
            "97/97 [==============================] - 569s 6s/step - loss: 0.6918 - accuracy: 0.6832 - val_loss: 0.8403 - val_accuracy: 0.5941\n",
            "Epoch 8/25\n",
            "97/97 [==============================] - 569s 6s/step - loss: 0.6605 - accuracy: 0.7110 - val_loss: 0.9992 - val_accuracy: 0.5588\n",
            "Epoch 9/25\n",
            "97/97 [==============================] - 570s 6s/step - loss: 0.6354 - accuracy: 0.7317 - val_loss: 1.0220 - val_accuracy: 0.5882\n",
            "Epoch 10/25\n",
            "97/97 [==============================] - 570s 6s/step - loss: 0.5336 - accuracy: 0.7833 - val_loss: 0.9943 - val_accuracy: 0.6118\n",
            "Epoch 11/25\n",
            "97/97 [==============================] - 571s 6s/step - loss: 0.5753 - accuracy: 0.7637 - val_loss: 0.9468 - val_accuracy: 0.6294\n",
            "Epoch 12/25\n",
            "97/97 [==============================] - 569s 6s/step - loss: 0.5619 - accuracy: 0.7781 - val_loss: 1.2105 - val_accuracy: 0.5941\n",
            "Epoch 13/25\n",
            "97/97 [==============================] - 569s 6s/step - loss: 0.5173 - accuracy: 0.7874 - val_loss: 1.0602 - val_accuracy: 0.5882\n",
            "Epoch 14/25\n",
            "97/97 [==============================] - 570s 6s/step - loss: 0.4272 - accuracy: 0.8338 - val_loss: 1.0199 - val_accuracy: 0.6647\n",
            "Epoch 15/25\n",
            "97/97 [==============================] - 570s 6s/step - loss: 0.4804 - accuracy: 0.8070 - val_loss: 1.1097 - val_accuracy: 0.5824\n",
            "Epoch 16/25\n",
            "97/97 [==============================] - 571s 6s/step - loss: 0.4160 - accuracy: 0.8328 - val_loss: 1.1007 - val_accuracy: 0.5941\n",
            "Epoch 17/25\n",
            "97/97 [==============================] - 571s 6s/step - loss: 0.3478 - accuracy: 0.8669 - val_loss: 1.1476 - val_accuracy: 0.5765\n",
            "Epoch 18/25\n",
            "97/97 [==============================] - 570s 6s/step - loss: 0.3760 - accuracy: 0.8638 - val_loss: 1.2481 - val_accuracy: 0.5588\n",
            "Epoch 19/25\n",
            "97/97 [==============================] - 571s 6s/step - loss: 0.3261 - accuracy: 0.8782 - val_loss: 1.0044 - val_accuracy: 0.6294\n",
            "Epoch 20/25\n",
            "97/97 [==============================] - 571s 6s/step - loss: 0.3027 - accuracy: 0.8875 - val_loss: 1.0320 - val_accuracy: 0.6765\n",
            "Epoch 21/25\n",
            "97/97 [==============================] - 571s 6s/step - loss: 0.3102 - accuracy: 0.8885 - val_loss: 0.9600 - val_accuracy: 0.6706\n",
            "Epoch 22/25\n",
            "97/97 [==============================] - 572s 6s/step - loss: 0.3079 - accuracy: 0.8854 - val_loss: 1.0629 - val_accuracy: 0.6059\n",
            "Epoch 23/25\n",
            "97/97 [==============================] - 570s 6s/step - loss: 0.2591 - accuracy: 0.9061 - val_loss: 1.6347 - val_accuracy: 0.6059\n",
            "Epoch 24/25\n",
            "97/97 [==============================] - 569s 6s/step - loss: 0.3460 - accuracy: 0.8617 - val_loss: 1.2075 - val_accuracy: 0.6059\n",
            "Epoch 25/25\n",
            "97/97 [==============================] - 569s 6s/step - loss: 0.2599 - accuracy: 0.8916 - val_loss: 1.0996 - val_accuracy: 0.6353\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1940090ad0>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.fit(X_train1,validation_data=X_test1,epochs=25,steps_per_epoch=97,validation_steps=17)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abf8c576",
      "metadata": {},
      "source": [
        "SAVING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lFG3M-NHBPMv",
      "metadata": {
        "id": "lFG3M-NHBPMv"
      },
      "outputs": [],
      "source": [
        "model1.save(\"Model1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3e5bfc",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model(\"Model1.h5\")\n",
        "\n",
        "\n",
        "def detect(frame):\n",
        "    img = cv2.resize(frame, (224, 224))\n",
        "    if(np.max(img) > 1):\n",
        "        img = img/255.0\n",
        "    img = np.array([img])\n",
        "    prediction = model.predict(img)\n",
        "    label = [\"front\", \"rear\", \"side\"]\n",
        "    preds = label[np.argmax(prediction)]\n",
        "    return preds"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Location.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a23257344542c70b70a498512f46db94a3a7f44d371a6893c689768adca66338"
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
